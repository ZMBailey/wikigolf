{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = requests.Session()\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "TITLE = 'Jurassic Park (novel)'\n",
    "\n",
    "PARAMS = {\n",
    "    'action': \"query\",\n",
    "    'titles': TITLE,\n",
    "    'prop': \"links\",\n",
    "    'pllimit': \"max\",\n",
    "    'format': \"json\",\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "data = R.json()\n",
    "#print(data['query']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ns': 0, 'title': '2000 AD (comics)'},\n",
       " {'ns': 0, 'title': 'A Case of Need'},\n",
       " {'ns': 0, 'title': 'Airframe (novel)'},\n",
       " {'ns': 0, 'title': 'Alfred A. Knopf'},\n",
       " {'ns': 0, 'title': 'Amazon (video game)'},\n",
       " {'ns': 0, 'title': 'Amber'},\n",
       " {'ns': 0, 'title': 'Amphibian'},\n",
       " {'ns': 0, 'title': 'Amusement park'},\n",
       " {'ns': 0, 'title': 'Ancient DNA'},\n",
       " {'ns': 0, 'title': 'Andrew Ferguson'},\n",
       " {'ns': 0, 'title': 'Auxotrophy'},\n",
       " {'ns': 0, 'title': 'BILBY Award'},\n",
       " {'ns': 0, 'title': 'Backdoor (computing)'},\n",
       " {'ns': 0, 'title': 'Barnes & Noble'},\n",
       " {'ns': 0, 'title': 'Battle at Big Rock'},\n",
       " {'ns': 0, 'title': 'Beyond Westworld'},\n",
       " {'ns': 0, 'title': 'Binary (novel)'},\n",
       " {'ns': 0, 'title': 'Biotechnology'},\n",
       " {'ns': 0, 'title': 'Bird'},\n",
       " {'ns': 0, 'title': 'Canopy Flyer'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['query']['pages'][list(data['query']['pages'])[0]]['links'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = data['query']['pages'][list(data['query']['pages'])[0]]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ns': 0, 'title': 'DNA'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0,len(links))\n",
    "links[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jurassic World: Original Motion Picture Soundtrack\n",
      "Jurassic World: Original Motion Picture Soundtrack\n"
     ]
    }
   ],
   "source": [
    "n = np.random.randint(0,len(links))\n",
    "NEXT = links[n]['title']\n",
    "\n",
    "PARAMS = {\n",
    "    'action': \"query\",\n",
    "    'titles': NEXT,\n",
    "    'prop': \"links\",\n",
    "    'pllimit': \"max\",\n",
    "    'format': \"json\",\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "next_data = R.json()\n",
    "print(links[n]['title'])\n",
    "print(next_data['query']['pages'][list(next_data['query']['pages'])[0]]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(TITLE):\n",
    "    PARAMS = {\n",
    "        'action': \"query\",\n",
    "        'titles': TITLE,\n",
    "        'prop': \"links\",\n",
    "        'pllimit': \"max\",\n",
    "        'format': \"json\",\n",
    "    }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS)\n",
    "    return R.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Jurassic Park (novel)\n",
      " 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Jurassic Park (novel)\n",
      "1 : Dragon curve\n",
      "2 : Blancmange curve\n",
      "3 : Archimedes\n",
      "4 : Menander\n",
      "5 : Akrai\n"
     ]
    }
   ],
   "source": [
    "start = input()\n",
    "hops = input()\n",
    "\n",
    "print(\"0 : \" + start)\n",
    "title = start\n",
    "for i in range(int(hops)):\n",
    "    response = get_links(title)\n",
    "    links = response['query']['pages'][list(response['query']['pages'])[0]]['links']\n",
    "    n = np.random.randint(0,len(links))\n",
    "    title = links[n]['title']\n",
    "    print(str(i+1) + \" : \" + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "jp = wikipedia.page('Jurassic Park (novel)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.collocations\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_50_most_common(page):\n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    tokens_raw = nltk.regexp_tokenize(page.content, pattern)\n",
    "    tokens = [word.lower() for word in tokens_raw]\n",
    "\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    stopwords_list += list(string.punctuation)\n",
    "    stopwords_list += ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "    words_stopped = [word for word in tokens if word not in stopwords_list]\n",
    "\n",
    "    freqdist = FreqDist(words_stopped)\n",
    "    return freqdist.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batman', 179),\n",
       " ('catwoman', 155),\n",
       " ('selina', 142),\n",
       " ('bruce', 50),\n",
       " ('two', 32),\n",
       " ('vol', 30),\n",
       " ('series', 29),\n",
       " ('story', 29),\n",
       " ('kyle', 28),\n",
       " ('one', 28),\n",
       " ('later', 28),\n",
       " (\"selina's\", 28),\n",
       " ('new', 28),\n",
       " ('gotham', 27),\n",
       " ('cat', 26),\n",
       " ('wayne', 25),\n",
       " ('comics', 24),\n",
       " ('time', 24),\n",
       " ('also', 24),\n",
       " ('relationship', 21),\n",
       " ('dc', 20),\n",
       " ('however', 20),\n",
       " ('earth', 20),\n",
       " ('city', 19),\n",
       " ('costume', 19),\n",
       " ('daughter', 19),\n",
       " ('joker', 17),\n",
       " ('black', 17),\n",
       " ('character', 16),\n",
       " ('mask', 16),\n",
       " ('first', 15),\n",
       " ('revealed', 15),\n",
       " ('end', 15),\n",
       " ('hush', 15),\n",
       " ('comic', 14),\n",
       " (\"batman's\", 14),\n",
       " ('holly', 14),\n",
       " ('life', 14),\n",
       " ('storyline', 14),\n",
       " ('ivy', 14),\n",
       " ('appears', 13),\n",
       " ('identity', 13),\n",
       " ('film', 13),\n",
       " ('returns', 13),\n",
       " ('years', 13),\n",
       " ('zatanna', 13),\n",
       " ('although', 11),\n",
       " ('romantic', 11),\n",
       " ('helena', 11),\n",
       " ('maggie', 11)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_50_most_common(wikipedia.page('Catwoman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
